% The documentation of the usage of CTUstyle -- the template for
% typessetting thesis by plain\TeX at CTU in Prague
% ---------------------------------------------------------------------
% Petr Olsak  Jan. 2013

% You can copy this file to your own file and do some changes.
% Then you can run:  pdfcsplain your-file

\input ctustyle  
\def\thednum{(\the\chapnum.\the\dnum)}
 % The template is included here.
%\input pdfuni    % Uncomment this if you need accented PDFoutlines
%\input opmac-bib % Uncomment this for direct reading of .bib database files 

\worktype [B] % Type: B = bachelor, M = master, D = Ph.D., O = other
                 % / the language: CZ = Czech, SK = Slovak, EN = English

\faculty    {F3}  % Type your faculty F1, F2, F3, etc.
            % use main language of your document here:
\department {Department of Radioelectronics}
\title      {Distributed signal processing in~radio communication networks}
%\subtitle   {}
            % \subtitle is optional
\author     {Jakub Kolář}
\date       {May 2017}
\supervisor {}  % One or more supervisors
\studyinfo  {Open Electronic Systems}  % Study programme etc.
%\workname   {Bachelor's thesis} % Used only if \worktype [O/*] (Other)
            % optional more information about the document:
\workinfo   {kolarj39@fel.cvut.cz}
            % Title / Subtitle in minor language:
\titleEN    {CTUstyle -- the user manual}
\subtitleEN {the plain\TeX{} template for theses at CTU}
            % If minor language is other than English
            % use \titleCZ, \subtitleCZ or \titleSK, \subtitleSK instead it.
\pagetwo    {}  % The text printed on the page 2 at the bottom.

\abstractEN { TBD

}
\abstractCZ {
   TBD.
}          

\keywordsEN {        Graph, Laplacian, Linear averaging consensus algorithm, Noisy updates, Estimation

}
\keywordsCZ {%
   Graf, Laplacián grafu, Lineární konsenzus, Aktualizace s rušením, Odhad parametru
}
\thanks {           % Use main language here
   TBD.
}
\declaration {      % Use main language here
   TBD.
  In Prague, 26. 5. 2017 % !!! Attention, you have to change this item.
   \signature % makes dots
}
\specification {\picw=\hsize \cinspic appendix/assignment.pdf}


%%%%% <--   % The place for your own macros is here.

%\draft     % Uncomment this if the version of your document is working only.
%\linespacing=1.7  % uncomment this if you need more spaces between lines
                   % Warning: this works only when \draft is activated!
%\savetoner        % Turns off the lightBlue backround of tables and
                   % verbatims, only for \draft version.
%\blackwhite       % Use this if you need really Black+White thesis.
%\onesideprinting  % Use this if you really don't use duplex printing. 

\makefront  % Mandatory command. Makes title page, acknowledgment, contents etc.
\input opmac-bib
\input introduction  % Files where the source of the document is prepared.
\input graph_theory
\input consensus_problem
\input distributed_estimation_in_wirelless_network
\input prilohy

\app Matlab scripts

\label[perfect_script]
\sec Averaging consensus algorithm with perfect communication

This is script $perfect\_communication\_example.m$ used in Examples \ref[ex3_5], \ref[ex3_6] and \ref[ex3_7]  to present the run of algorithm. In this case we do not use the built-in matlab functions to compute desired values, only to check them.

%\picw=0.7\hsize % obrázek na šířku sazby
%\cinspic scripts_export/script_perfect_communication_example.pdf

\begtt
% Run of averaging consensus algorithm with perfect communication                   
clear all;
s=[1 1 2 2 3 3 3 4 4 4 5 6 7 8 8 9 9 10  ];%source vertices
t=[2 3 4 5 7 10 5 5 6 7 6 7 5 1 2 10 7 8];%destination vertices
w=[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]; %weights of edges
G = graph(s,t,w); %create graph G with parameters s, t, w
iterations = 30;
for i= 1:length(s) %A is adjacency matrix; A(i,j)=1 <=> exists edge (i,j)
   A(s(i),t(i))=1;
   A(t(i),s(i))=1; 
end
checkA=isequal(A, adjacency(G)); %check adjacency matrix
M=0; %M is the highest degree of vertex
for i=1:size(A)
    sumRadek=sum(A(i,:))
    if sumRadek>=M
        M=sumRadek;        
    end
end
for i = 1:size(A)
    D(i,i)=sum(A(i,:))%D is degree matrix
end
L=D-A; %Laplacian matrix
checkLaplacian=isequal(laplacian(G),L); %check Laplacian 
for i= 1:length(s) %Incidence matrix
    E(s(i),i)=1;
    E(t(i),i)=-1;
end
L2=E*transpose(E); %another way to compute Laplacian
checkLaplacian2=isequal(laplacian(G),L2); %check Laplacian 
I=L*ones(max(s)); %check that Laplacian rows sum up to 1
D = eig(L,'matrix');%diagonal matrix of eigenvalues of laplacian
L_eig=eig(L);
alpha=2/(L_eig(2)+L_eig(max(s)))

for i = 1:max(s)
node_initial_value(i)=i; %initialization of values to average
%running_value(i+1,j)=node_value(j);
running_value(1,i)=node_initial_value(i);
running_value_Error(1,i)=-node_initial_value(i)+mean(node_initial_value);
end
for i= 1:max(s)
final_value(i)=mean(node_initial_value); %expected average value
end
node_value=node_initial_value; %inicialization of nodes values
running_value_Error(1,:)=final_value-node_initial_value;
for i=1:iterations+1
discrete_time(i)= i-1;
end
for i = 1:iterations;
    IT=eye([max(s) max(s)])-alpha*L; %iteratation Perron matrix
    node_value=node_value;
    node_value= node_value* IT;
    for j=1:max(s)
            running_value(i+1,j)=node_value(j);
            running_value_Error(i+1,j)=final_value(j)-node_value(j);
    %node_value(5)=3; uncomment for convergence to v_3 initial value
    end
end

figure;
plot(discrete_time, running_value(:,:));
ttl1=title( 'Run of algorithm with updates affected by AWGN '  )
ttl1=set(ttl1,'Interpreter','latex','FontSize', 15);
xlbl1=xlabel('Iterations [-]');
xlbl1=set(xlbl1,'Interpreter','latex');
ylbl1=ylabel('Value [-]');
ylbl1=set(ylbl1,'Interpreter','latex');
grid;
figure;
grid on
plot(discrete_time, running_value_Error(:,:));
title('shrinking of error');
grid on
figure;
plot(G); %plot graph G
\endtt

\nextoddpage

\label[noise_script]
\sec Averaging consensus algorithm with noisy observation and updates using decreasing step size

 This is script $script\_noisy\_updates\_gamma.m$ used in Example \label[ex_conv_noise_gamma] to present simple way to preserve convergence in case of noisy updates.

\begtt
% Run of averaging consensus algorithm with noisy 
% updates using descending step size scheme gamma=a/(1+b)^c                     


%% graph definition
clear all; clc;
variance_noise=0.1; %variance of the gaussian noise added to the updates
iterations =5000; %number of iterations of the algorithm
nodes=60; %number of graph nodes
G=graph(bucky); % using matlab default graph bucky
% i.e. 60 nodes with degree 3
%% variables initialization
equiv_noise_vector=zeros(1,nodes); 
x_0=zeros(1,nodes);
MSE_ave=zeros(zeros(1,iterations+1));
VAR=zeros(zeros(1,iterations+1));
MSE_act=zeros(zeros(1,iterations+1));
diag_D=zeros(nodes,nodes);
%plot the used graph
figure;
plot(G)
deg=degree(G);
for p=1:nodes
   diag_D(p,p)=deg(p); 
end
%observation initialization const 10 + wgn with variance 1 
for i=1:nodes     %initialize measurement
    x_0(i)=(10+wgn(1,1,log10(10*variance_noise)));    
end

%% variables definition
x_est_run(1,:) = x_0;
MSE_act(1)= sum((x_0-mean(x_0)).^2);
MSE_ave(1)=MSE_act(1);
VAR(1)=var(x_0);
noise_matrix=zeros(nodes);
%Laplacian using library functions
A=adjacency(G); %adjacency matrix
L=laplacian(G); %laplacian matrix
eig_L=eig(L);%eigenvalues of Laplacian
gamma=2/(eig_L(2)+eig_L(nodes));%the best possible coefficient
mean_0=mean(x_0);%value to converge to

%% Iterations of the algorithm
for i=1:iterations
   gamma=1/(i+42)^0.75; %selected descending step size
   P=eye(nodes)- gamma* L; %Perron matrix

   for j=1:nodes %computation of the nise affecting updates exchange
      noise_matrix(j,:)=wgn(nodes,1,10*log10(variance_noise)) ;
      noise_matrix(j,j)=0 ;
   end
    equiv_noise_matrix= P*noise_matrix;
   for j=1:nodes
     equiv_noise_vector(j)= equiv_noise_matrix(j,j);
   end
   x_est_run(i+1,:)=  P*x_est_run(i,:)'+equiv_noise_vector';  
end

%calculation of the run statistics
for i=1:iterations
  MSE_ave(i+1)= sum((x_est_run(i+1,:)-mean(x_0)).^2)/nodes;
  MSE_act(i+1)= sum((x_est_run(i+1,:)-mean(x_est_run(i+1,:))).^2)/nodes;   
  VAR(i+1)= var(x_est_run(i+1,:));
end

%%  Plot results
figure;
plot(0:iterations, x_est_run(:,:));
ttl1=title( 'Values in nodes'  )
ttl1=set(ttl1,'Interpreter','latex','FontSize', 15);
xlbl1=xlabel('Iterations [-]');
xlbl1=set(xlbl1,'Interpreter','latex');
ylbl1=ylabel('Value [-]');
ylbl1=set(ylbl1,'Interpreter','latex');
grid;

figure;
loglog(0:iterations, MSE_ave(:)   );
ttl1=title( 'Mean square error w.r.t. initial average '  )
ttl1=set(ttl1,'Interpreter','latex','FontSize', 15);
xlbl1=xlabel('Iterations [-]');
xlbl1=set(xlbl1,'Interpreter','latex');
ylbl1=ylabel('MSE [-]');
ylbl1=set(ylbl1,'Interpreter','latex');
grid;

figure;
loglog(0:iterations, VAR(:));
ttl1=title( 'Variance '  );
ttl1=set(ttl1,'Interpreter','latex','FontSize', 15);
xlbl1=xlabel('Iterations [-]');
xlbl1=set(xlbl1,'Interpreter','latex');
ylbl1=ylabel('Variance [-]');
ylbl1=set(ylbl1,'Interpreter','latex');
grid;

\endtt

\bye
